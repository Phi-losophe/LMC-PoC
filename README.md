# LMC-PoC
Proof of Concept et tests pour la Loi de Minimisation de l'Entropie Cognitive

# LMC-Law: Cognitive Entropy Minimization

![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)
![Status](https://img.shields.io/badge/status-research_prototype-orange)
![License](https://img.shields.io/badge/license-MIT-green)

## üß† Introduction

Ce d√©p√¥t contient l'impl√©mentation de r√©f√©rence (Proof of Concept) de la **Loi de Minimisation de l‚ÄôEntropie Cognitive (LMC)**.

La **LMC** est une proposition th√©orique mod√©lisant la prise de d√©cision cognitive comme un probl√®me d'optimisation thermodynamique. Elle postule que tout syst√®me intelligent (biologique ou artificiel) s√©lectionne les structures d'information qui maximisent la coh√©rence contextuelle tout en minimisant leur entropie interne (co√ªt √©nerg√©tique de traitement).

## üìê Le Mod√®le Math√©matique

Le syst√®me √©value des structures candidates $s$ dans un contexte $\Omega$ selon la fonction de co√ªt suivante :

$$Score(s) = \frac{\mathcal{C}(s | \Omega)}{H(s) + \epsilon}$$

O√π :
* **$\mathcal{C}$ (Coh√©rence)** : Calcul√©e via la **Similarit√© Cosinus** entre les vecteurs d'embeddings du contexte et du candidat.
* **$H$ (Entropie)** : Approxim√©e via le taux de compression (Zlib/Deflate) ou l'Entropie de Shannon, repr√©sentant la complexit√© descriptive (MDL).
* **$\epsilon$** : Constante de r√©gularisation ($1e^{-6}$).



[Image of vector space model NLP]

*Visualisation conceptuelle de l'espace vectoriel utilis√© pour calculer C (la coh√©rence).*

## üöÄ Installation

1. Clonez ce d√©p√¥t :
```bash
git clone [https://github.com/votre-user/lmc-law.git](https://github.com/votre-user/lmc-law.git)
cd lmc-law
